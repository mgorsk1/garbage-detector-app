{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_with_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEOrmuLYMunn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5mmP6NNMn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install lime\n",
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3mj59jUO9Y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IyGA7gbM0nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izoepYA_M2GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_dir = 'My Drive/projects/ING/Experiment_week/garbage_segmentation/'\n",
        "data_dir = os.path.join(project_dir, 'data', 'raw')\n",
        "train_data_dir = os.path.join(data_dir, \"train\")\n",
        "test_data_dir = os.path.join(data_dir, \"test\")\n",
        "models_dir = project_dir + \"/models\"\n",
        "os.listdir(project_dir + \"/data/raw/train/paper\")[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfIS_1RuM5cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = os.listdir(project_dir + \"/data/raw/train\")\n",
        "\n",
        "def to_categorical(labels, label_to_index):\n",
        "    labels_int = pd.Series(labels).map(label_to_index)\n",
        "    return tf.keras.utils.to_categorical(labels_int, num_classes=len(label_to_index))\n",
        "\n",
        "label_to_index = dict(zip(classes, range(len(classes))))\n",
        "index_to_label = {v: k for k, v in label_to_index.items()}\n",
        "classes, label_to_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiByTKFpNB7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers, losses\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVowQb-wNGoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height, img_width = 224, 224\n",
        "target_size = (img_height, img_width)\n",
        "batch_size = 32\n",
        "nb_epochs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uccyo5YNNJ7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.1,\n",
        "    #horizontal_flip=True,\n",
        "    #vertical_flip=True,\n",
        "    #shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    rotation_range=30,\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    classes=classes,\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    classes=classes,\n",
        "    shuffle=True,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ").flow_from_directory(\n",
        "    directory=test_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    shuffle=False,\n",
        "    classes=classes,\n",
        "    batch_size=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eujl5jXSxkBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it = ImageDataGenerator(\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    rotation_range=30,\n",
        "    validation_split=0.002,\n",
        ").flow_from_directory(\n",
        "    train_data_dir, \n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=1,\n",
        "    classes=classes,\n",
        "    subset='validation',\n",
        "    shuffle=True,\n",
        "    seed=1\n",
        ")\n",
        "print(it.n, len(it.filenames), len(it))\n",
        "# generate samples and plot\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  batch = it.next()\n",
        "  image = batch[0][0].astype('uint8')\n",
        "  plt.imshow(image, origin='lower')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-ULTf65NTJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_generator.class_indices, validation_generator.class_indices, test_generator.class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNox_T25Nijn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    # BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(200, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.15),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dropout(0.15),\n",
        "    Dense(train_generator.num_classes, activation='softmax')                    \n",
        "])\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.adam(lr=1e-3),\n",
        "    loss=losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTArk8A7Nx8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epochs = 8\n",
        "data_augmentation_factor = 4.0\n",
        "\n",
        "model_filepath=os.path.join(models_dir, \"model_ver1_weights.best.hdf5\")\n",
        "checkpoint = ModelCheckpoint(model_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = data_augmentation_factor * train_generator.n // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = data_augmentation_factor * validation_generator.n // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    callbacks = callbacks_list\n",
        ")\n",
        "model.load_weights(model_filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MoOqvd5bq8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(model_filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7sFjhYOmr7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(os.path.join(models_dir, \"model_ver1.h5\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ardYJSay0eBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "# model = tf.keras.models.load_model(os.path.join(models_dir, \"far_model_20200422.h5\"))\n",
        "model = load_model(os.path.join(models_dir, \"model_ver1.h5\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DRYYUYbN_zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate_generator(test_generator, steps=test_generator.n, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-bhUTXjBzF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_pred = model.predict_generator(validation_generator, steps=validation_generator.n, verbose=1)\n",
        "np.mean(valid_pred, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_3cFgDHPRY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict_generator(test_generator, steps=test_generator.n, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGNGHJNRBskJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(test_pred, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Xes9Skcl8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.DataFrame({\n",
        "    'name': test_generator.filenames,\n",
        "    'pred': np.argmax(test_pred, axis=1),\n",
        "    'pred_pr': np.max(test_pred, axis=1),\n",
        "    'target': test_generator.classes\n",
        "})\n",
        "test_df.groupby('pred').size().sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcH4UQb7cp3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.groupby(['target', 'pred']).size().unstack(level=1).fillna(0).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcAq0t7V4C4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "nc = len(classes)\n",
        "fig, axs = plt.subplots(nrows=nc, ncols=nc, figsize=(nc*3, nc*3))\n",
        "for i, j in itertools.product(range(nc), repeat=2):\n",
        "  sel = test_df[(test_df.target==i) & (test_df.pred==j)].sort_values(by=['pred_pr', 'name'], ascending=[False, True])\n",
        "  ax = axs[i][j]\n",
        "  if len(sel) > 0:\n",
        "    filename = os.path.join(test_generator.directory, sel.iloc[0]['name'])\n",
        "    # print(i, j, filename)\n",
        "    img = tf.keras.preprocessing.image.load_img(filename, target_size=target_size)\n",
        "    ax.imshow(img, origin='lower')\n",
        "    ax.set_title(f'target: {classes[i]}\\npred: {classes[j]}')\n",
        "  else:\n",
        "    ax.set_axis_off()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUSTiq9sc9wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3zvbI_BJZrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\n",
        "    classification_report(\n",
        "        test_df['target'], \n",
        "        test_df['pred'], \n",
        "        target_names=classes\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCAm9sT-Jo7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(filename):\n",
        "  raw_img = tf.keras.preprocessing.image.load_img(filename, target_size=target_size)\n",
        "  img = tf.keras.preprocessing.image.img_to_array(raw_img)\n",
        "  img = preprocess_input(img)\n",
        "  pred = model.predict(np.stack([img]))[0]\n",
        "  pred_class = classes[np.argmax(pred)]\n",
        "  target_class = filename.split(\"/\")[-2]\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(raw_img, origin='lower')\n",
        "  plt.title(f\"target: {target_class} prediction: {pred_class}, pr: {np.max(pred):.2f}\")\n",
        "  plt.show()\n",
        "predict(test_generator.directory + \"/\" + test_generator.filenames[60])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYUy0W4uJ4zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lime\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "def explain(filename):\n",
        "  raw_img = tf.keras.preprocessing.image.load_img(filename, target_size=target_size)\n",
        "  img = tf.keras.preprocessing.image.img_to_array(raw_img)\n",
        "\n",
        "  def predict_fn(img):\n",
        "    inp = preprocess_input(img)\n",
        "    return model.predict(inp)\n",
        "\n",
        "  explanation = explainer.explain_instance(img, predict_fn, top_labels=5, hide_color=0, num_samples=1000)\n",
        "\n",
        "  temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(tf.keras.preprocessing.image.array_to_img(mark_boundaries(temp / 2 + 0.5, mask)), origin='lower')\n",
        "  plt.show()\n",
        "\n",
        "explain(test_generator.directory + \"/\" + test_generator.filenames[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAYprgWpRDBg",
        "colab_type": "text"
      },
      "source": [
        "# misc experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQTHZmfzNKkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "def adv_preprocessing(image):\n",
        "    #loading imageswith\n",
        "\n",
        "    preimgs = []\n",
        "    img = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    #Setting dimensions to resize\n",
        "    height = 224\n",
        "    width = 224\n",
        "    \n",
        "    dim = (width, height)\n",
        "    res = cv2.resize(img, dim, interpolation = cv2.INTER_LINEAR)\n",
        "    preimgs.append(res)\n",
        "        \n",
        "#Removing noise from image - Gaussian blur\n",
        "    \n",
        "    blurred_img = cv2.GaussianBlur(res, (5,5),0)\n",
        "    preimgs.append(blurred_img)\n",
        "\n",
        "    #Segmentation \n",
        "    #------------------------------------------------------------------\n",
        "    image = res\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    ret,thresh = cv2.threshold(gray, 0,255,cv2.THRESH_BINARY+ cv2.THRESH_OTSU)\n",
        "    \n",
        "    #More noise removal\n",
        "    #------------------------------------------------------------------\n",
        "    kernal = np.ones((3,3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernal, iterations=2)\n",
        "    \n",
        "    #Sure background area\n",
        "    sure_bg = cv2.dilate(opening, kernal, iterations = 3)\n",
        "    \n",
        "    #Finding foreground area\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "    \n",
        "    # Finding unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "    \n",
        "    #Seperating different objects with different backgrounds\n",
        "    #Markers labelling\n",
        "    ret, markers  = cv2.connectedComponents(sure_fg)\n",
        "    #Add one to all labels so that sure background is 0 not 1\n",
        "    markers = markers+1\n",
        "    \n",
        "    #Mark the unknown region with 0\n",
        "    markers[unknown == 255] = 0\n",
        "    \n",
        "    markers = cv2.watershed(res, markers)\n",
        "    res[markers == -1] = [255,0,0]\n",
        "    placeholder = np.random.rand(224,224)\n",
        "    #Displaying the markers on image\n",
        "    markers = np.dstack([markers,np.zeros((224,224)), placeholder])\n",
        "    #Adding \n",
        "    preimgs.append(res)\n",
        "    preimgs.append(markers)\n",
        "    \n",
        "    return preimgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUrrnaVcOYaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = test_generator.directory + \"/\" + test_generator.filenames[60]\n",
        "img = tf.keras.preprocessing.image.load_img(filename, target_size=target_size)\n",
        "plt.imshow(img, origin='lower')\n",
        "plt.show()\n",
        "res = adv_preprocessing(filename)[:3]\n",
        "fig, axs = plt.subplots(ncols=len(res), figsize=(12, 4))\n",
        "for i, ax in zip(res, axs):\n",
        "  i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
        "  ax.imshow(tf.keras.preprocessing.image.array_to_img(i), origin='lower')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lj0jisaPANi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}